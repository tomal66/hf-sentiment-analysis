{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q_dDKIt_W86",
        "outputId": "2138bac5-4638-4493-f3b5-30fc2ce3b3bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /home/tomal66/jupyter_env/lib/python3.12/site-packages (0.18.0)\n",
            "Requirement already satisfied: datasets in /home/tomal66/jupyter_env/lib/python3.12/site-packages (3.5.0)\n",
            "Requirement already satisfied: pandas in /home/tomal66/jupyter_env/lib/python3.12/site-packages (2.2.3)\n",
            "Requirement already satisfied: matplotlib in /home/tomal66/jupyter_env/lib/python3.12/site-packages (3.10.1)\n",
            "Requirement already satisfied: nltk in /home/tomal66/jupyter_env/lib/python3.12/site-packages (3.9.1)\n",
            "Requirement already satisfied: tqdm in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torchtext) (2.6.0)\n",
            "Requirement already satisfied: numpy in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torchtext) (2.1.3)\n",
            "Requirement already satisfied: filelock in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from datasets) (3.11.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: click in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from requests->torchtext) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from requests->torchtext) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from requests->torchtext) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (78.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/tomal66/jupyter_env/lib/python3.12/site-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext datasets pandas matplotlib nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0628f-IT_mSC"
      },
      "outputs": [],
      "source": [
        "import re, json, random, math, time\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "DATASET_ROOT = \"hf://datasets/Sp1786/multiclass-sentiment-analysis-dataset/\"\n",
        "SPLITS       = dict(train=\"train_df.csv\",\n",
        "                    validation=\"val_df.csv\",\n",
        "                    test=\"test_df.csv\")\n",
        "\n",
        "VOCAB_SIZE   = 20_000          # incl. PAD+UNK\n",
        "MAX_LEN      = 200\n",
        "EMBED_DIM    = 128\n",
        "HIDDEN_DIM   = 64\n",
        "NUM_CLASSES  = 3\n",
        "LR           = 3e-3\n",
        "EPOCHS       = 10\n",
        "BATCH_SIZE   = 128\n",
        "DEVICE       = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "ROOT_DIR     = Path.cwd()            # project root\n",
        "MODEL_PT     = ROOT_DIR / \"sentiment_bilstm_best.pt\"\n",
        "VOCAB_JSON   = ROOT_DIR / \"vocab.json\"   # handy for later re‑use\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o2u-RUTEoVR",
        "outputId": "9dff2c83-0aff-442d-cac9-b4c5d45ade6b"
      },
      "outputs": [],
      "source": [
        "def clean_text(text:str) -> str:\n",
        "    if pd.isna(text): return \"\"\n",
        "    text = re.sub(r'<.*?>',  '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return text.lower().strip()\n",
        "\n",
        "dfs = {name: pd.read_csv(DATASET_ROOT + fn) for name,fn in SPLITS.items()}\n",
        "for df in dfs.values():\n",
        "    df[\"text\"] = df[\"text\"].fillna(\"\").apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QoGqxjpHEvzd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/tomal66/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['app', 'im', 'day', 'like', 'good', 'time', 'get', 'love', 'dont', 'one']\n"
          ]
        }
      ],
      "source": [
        "PAD, UNK = \"<PAD>\", \"<UNK>\"\n",
        "\n",
        "# Skip stop words\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "STOP_WORDS = set(stopwords.words(\"english\"))\n",
        "\n",
        "counter = Counter()\n",
        "for text in dfs[\"train\"][\"text\"]:\n",
        "    tokens = text.split()\n",
        "    filtered = [w for w in tokens if w not in STOP_WORDS]\n",
        "    counter.update(filtered)\n",
        "\n",
        "most_common = [w for w,_ in counter.most_common(VOCAB_SIZE-2)]\n",
        "itos = [PAD, UNK] + most_common\n",
        "stoi = {tok:i for i,tok in enumerate(itos)}\n",
        "\n",
        "print(most_common[:10])\n",
        "\n",
        "\n",
        "with open(VOCAB_JSON, \"w\") as f: json.dump(itos, f)\n",
        "\n",
        "PAD_IDX = stoi[PAD]; UNK_IDX = stoi[UNK]\n",
        "\n",
        "def encode_pad(text:str, max_len:int=MAX_LEN):\n",
        "    seq = [stoi.get(tok, UNK_IDX) for tok in text.split()]\n",
        "    seq = seq[:max_len] + [PAD_IDX]*(max_len-len(seq))\n",
        "    return torch.tensor(seq, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UeDQd1w0Eydv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      id                                               text  label sentiment\n",
            "0   9536                     cooking microwave pizzas yummy      2  positive\n",
            "1   6135  any plans of allowing sub tasks to show up in ...      1   neutral\n",
            "2  17697  i love the humor i just reworded it like sayin...      2  positive\n",
            "3  14182                       naw idk what ur talkin about      1   neutral\n",
            "4  17840           that sucks to hear i hate days like that      0  negative\n"
          ]
        }
      ],
      "source": [
        "class SentDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.seqs  = [encode_pad(t) for t in df[\"text\"]]\n",
        "        self.labels = torch.tensor(df[\"label\"].values, dtype=torch.long)\n",
        "    def __len__(self): return len(self.labels)\n",
        "    def __getitem__(self, idx): return self.seqs[idx], self.labels[idx]\n",
        "\n",
        "train_ds = SentDataset(dfs[\"train\"]);  val_ds = SentDataset(dfs[\"validation\"])\n",
        "test_ds  = SentDataset(dfs[\"test\"])\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE)\n",
        "test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE)\n",
        "\n",
        "print(dfs[\"train\"].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N80P8BU7E35Z"
      },
      "outputs": [],
      "source": [
        "class BiLSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_sz, embed_dim, hidden_dim, num_cls, pad_idx):\n",
        "        super().__init__()\n",
        "        self.emb  = nn.Embedding(vocab_sz, embed_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim,\n",
        "                            bidirectional=True, batch_first=True)\n",
        "        self.drop1 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc1  = nn.Linear(hidden_dim*2, 32)\n",
        "        self.bn   = nn.BatchNorm1d(32)\n",
        "        self.drop2 = nn.Dropout(0.6)\n",
        "        self.out  = nn.Linear(32, num_cls)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.emb(x)\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        h = torch.cat((h_n[0], h_n[1]), dim=1)\n",
        "        h = self.drop1(h)\n",
        "        h = F.relu(self.fc1(h))\n",
        "        h = self.bn(h)\n",
        "        h = self.drop2(h)\n",
        "        return self.out(h)\n",
        "\n",
        "model = BiLSTMClassifier(len(itos), EMBED_DIM,\n",
        "                         HIDDEN_DIM, NUM_CLASSES, PAD_IDX).to(DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WK-FLThFBEt",
        "outputId": "4815db0b-82cb-477f-d744-aa6ec9c0e330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  1 | train loss 1.0538 | val acc 55.716%\n",
            "Epoch  2 | train loss 0.8733 | val acc 63.305%\n",
            "Epoch  3 | train loss 0.7486 | val acc 65.668%\n",
            "Epoch  4 | train loss 0.6595 | val acc 65.648%\n",
            "Epoch  5 | train loss 0.5844 | val acc 66.148%\n",
            "Epoch  6 | train loss 0.5171 | val acc 65.187%\n",
            "Epoch  7 | train loss 0.4692 | val acc 65.360%\n",
            "Epoch  8 | train loss 0.4160 | val acc 64.380%\n",
            "Epoch  9 | train loss 0.3749 | val acc 64.784%\n",
            "Epoch 10 | train loss 0.3425 | val acc 64.592%\n"
          ]
        }
      ],
      "source": [
        "opt  = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "crit = nn.CrossEntropyLoss()\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train();   running = 0\n",
        "    for X,y in train_dl:\n",
        "        X,y = X.to(DEVICE), y.to(DEVICE)\n",
        "        opt.zero_grad() # Set gradients to zero\n",
        "        loss = crit(model(X), y)\n",
        "        loss.backward(); opt.step() # Gradient Descent\n",
        "        running += loss.item()*len(y)\n",
        "\n",
        "    # validation\n",
        "    model.eval();  correct=total=0\n",
        "    with torch.no_grad():\n",
        "        for X,y in val_dl:\n",
        "            X,y = X.to(DEVICE), y.to(DEVICE)\n",
        "            pred = model(X).argmax(1)\n",
        "            correct += (pred==y).sum().item()\n",
        "            total   += len(y)\n",
        "    val_acc = correct/total\n",
        "    print(f\"Epoch {epoch:2d} | train loss {running/len(train_ds):.4f}\"\n",
        "          f\" | val acc {val_acc:.3%}\")\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save({\"state_dict\": model.state_dict(),\n",
        "                    \"itos\": itos}, MODEL_PT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7leCzIDFitb",
        "outputId": "5a975d0c-dc4f-4bf0-86ce-3b92c7b8cad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Utterly disappointing; the acting felt wooden.', 'negative'), (\"Let's play a game of chess instead.\", 'negative'), (\"Can't wait to see the new movie!\", 'negative')]\n"
          ]
        }
      ],
      "source": [
        "INDEX2LABEL = {0:\"negative\", 1:\"neutral\", 2:\"positive\"}\n",
        "\n",
        "def predict(texts):\n",
        "    model.eval()\n",
        "    X = torch.stack([encode_pad(clean_text(t)) for t in texts]).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        preds = model(X).argmax(1).cpu().numpy()\n",
        "    return [INDEX2LABEL[i] for i in preds]\n",
        "\n",
        "samples = [\"Utterly disappointing; the acting felt wooden.\",\n",
        "           \"Let's play a game of chess instead.\",\n",
        "           \"Can't wait to see the new movie!\"]\n",
        "print(list(zip(samples, predict(samples))))\n",
        "\n",
        "\n",
        "# Visualize NN model on input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9VWZzJjFp5B",
        "outputId": "a989dcdf-24e2-4ae6-f9a7-e9247e7d10b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BiLSTMClassifier(\n",
              "  (emb): Embedding(20000, 128, padding_idx=0)\n",
              "  (lstm): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
              "  (drop1): Dropout(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=128, out_features=32, bias=True)\n",
              "  (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (drop2): Dropout(p=0.6, inplace=False)\n",
              "  (out): Linear(in_features=32, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ckpt   = torch.load(MODEL_PT, map_location=\"cpu\")\n",
        "itos   = ckpt[\"itos\"]\n",
        "stoi   = {tok:i for i,tok in enumerate(itos)}\n",
        "PAD_IDX, UNK_IDX = stoi[\"<PAD>\"], stoi[\"<UNK>\"]\n",
        "\n",
        "def encode_pad_reload(text, max_len=MAX_LEN):\n",
        "    seq = [stoi.get(tok, UNK_IDX) for tok in clean_text(text).split()]\n",
        "    seq = seq[:max_len] + [PAD_IDX]*(max_len-len(seq))\n",
        "    return torch.tensor(seq)\n",
        "\n",
        "reloaded = BiLSTMClassifier(len(itos), EMBED_DIM,\n",
        "                            HIDDEN_DIM, NUM_CLASSES, PAD_IDX)\n",
        "reloaded.load_state_dict(ckpt[\"state_dict\"])\n",
        "reloaded.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: negative (reloaded model)\n"
          ]
        }
      ],
      "source": [
        "# Sanity check on reloaded model\n",
        "\n",
        "# Extremely negative\n",
        "text = \"This is the worst movie I have ever seen.\"\n",
        "X = encode_pad_reload(text).unsqueeze(0)\n",
        "X = X.to(DEVICE)\n",
        "with torch.no_grad():\n",
        "    pred = reloaded(X).argmax(1).cpu().numpy()\n",
        "print(f\"Prediction: {INDEX2LABEL[pred[0]]} (reloaded model)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchviz graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'bilstm_graph.png'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchviz import make_dot\n",
        "\n",
        "# 1) Pick a sample text and encode it\n",
        "sample_text = \"I absolutely loved the cinematography but the plot was dull.\"\n",
        "indices = encode_pad_reload(sample_text).unsqueeze(0).to(DEVICE)  # shape (1, MAX_LEN)\n",
        "\n",
        "# 2) Run a forward pass and capture the output\n",
        "model.eval()\n",
        "out = model(indices)  # shape (1, NUM_CLASSES)\n",
        "\n",
        "# 3) Build the graph\n",
        "#    params=dict(model.named_parameters()) will link the parameter tensors into the graph\n",
        "dot = make_dot(out, params=dict(model.named_parameters()))\n",
        "\n",
        "# 4) Render to a file (will produce `bilstm_graph.png` and `bilstm_graph`)\n",
        "dot.format = 'png'\n",
        "dot.render('bilstm_graph')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "jupyter_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
